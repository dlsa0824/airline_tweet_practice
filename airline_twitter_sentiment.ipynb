{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 航空twitter的資料拿來情緒分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SpatialDropout1D, Bidirectional\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=pd.read_csv(\"airline_twitter_dataset/Tweets.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只留下需要的資料\n",
    "tweet=tweet.drop(columns=['tweet_id','airline_sentiment_confidence','negativereason','negativereason_confidence'\n",
    "                   ,'airline','airline_sentiment_gold','name','negativereason_gold','retweet_count','tweet_coord'\n",
    "                   ,'tweet_created','tweet_location','user_timezone',])\n",
    "tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet['text2']=tweet['text'].str.replace('@VirginAmerica ','',regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
    "\n",
    "# stemmer\n",
    "stemmer=SnowballStemmer('english')\n",
    "lemma=WordNetLemmatizer()\n",
    "porter=PorterStemmer()  #porter stemming\n",
    "lancaster=LancasterStemmer()  #lancaster stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 對資料作處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>what said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>plu you ve ad commerci to the experi ... tacki .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>I didn t today ... must mean I need to take an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>it s realli aggress to blast obnoxi entertain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>and it s a realli big bad thing about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>serious would pay 30 a flight for seat that di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>ye nearli everi time I fli VX thi ear worm won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>realli miss a prime opportun for men without h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>well I didn t but now I DO -D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>it wa amaz and arriv an hour earli . you re to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                @VirginAmerica What @dhepburn said.   \n",
       "1          positive  @VirginAmerica plus you've added commercials t...   \n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "4          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...   \n",
       "6          positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "7           neutral  @VirginAmerica Really missed a prime opportuni...   \n",
       "8          positive    @virginamerica Well, I didn't…but NOW I DO! :-D   \n",
       "9          positive  @VirginAmerica it was amazing, and arrived an ...   \n",
       "\n",
       "                                               text2  \n",
       "0                                        what said .  \n",
       "1   plu you ve ad commerci to the experi ... tacki .  \n",
       "2  I didn t today ... must mean I need to take an...  \n",
       "3  it s realli aggress to blast obnoxi entertain ...  \n",
       "4           and it s a realli big bad thing about it  \n",
       "5  serious would pay 30 a flight for seat that di...  \n",
       "6  ye nearli everi time I fli VX thi ear worm won...  \n",
       "7  realli miss a prime opportun for men without h...  \n",
       "8                      well I didn t but now I DO -D  \n",
       "9  it wa amaz and arriv an hour earli . you re to...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for text in range(len(tweet)):\n",
    "    review=str(tweet.loc[text,'text'])\n",
    "    review=re.sub(r'@[A-Za-z0-9]+','',review)\n",
    "    review=re.sub('[^a-zA-Z0-9-_.]', ' ', review)\n",
    "    review=[porter.stem(w) for w in word_tokenize(str(review))]  #這邊是選用porter stemming\n",
    "#     re.sub(r'@[A-Za-z0-9]+','',df.text[343])\n",
    "#     review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
    "    review=' '.join(review)\n",
    "    tweet.loc[text,'text2']=review\n",
    "tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words=' '.join(tweet['text2'])\n",
    "all_words=word_tokenize(all_words)\n",
    "dist=FreqDist(all_words)\n",
    "num_unique_word=len(dist)\n",
    "num_unique_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出最長的句子有幾個字\n",
    "r_len=list()\n",
    "for text in range(len(tweet)):\n",
    "    word=word_tokenize(tweet.loc[text,'text2'])\n",
    "    l=len(word)\n",
    "    r_len.append(l)\n",
    "max_review_len=np.max(r_len)\n",
    "max_review_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>what said .</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>plu you ve ad commerci to the experi ... tacki .</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>I didn t today ... must mean I need to take an...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>it s realli aggress to blast obnoxi entertain ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>and it s a realli big bad thing about it</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                @VirginAmerica What @dhepburn said.   \n",
       "1          positive  @VirginAmerica plus you've added commercials t...   \n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "4          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                               text2  label  \n",
       "0                                        what said .    0.0  \n",
       "1   plu you ve ad commerci to the experi ... tacki .    2.0  \n",
       "2  I didn t today ... must mean I need to take an...    0.0  \n",
       "3  it s realli aggress to blast obnoxi entertain ...    1.0  \n",
       "4           and it s a realli big bad thing about it    1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.loc[tweet['airline_sentiment']=='positive', 'label'] = 2\n",
    "tweet.loc[tweet['airline_sentiment']=='negative', 'label'] = 1\n",
    "tweet.loc[tweet['airline_sentiment']=='neutral', 'label'] = 0\n",
    "tweet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X = tweet['text2'].to_numpy()\n",
    "Y = tweet['label'].to_numpy()\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11712 2928\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train).reshape(-1,1)\n",
    "Y_validation = le.transform(Y_validation).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#對label做one-hot encoding\n",
    "ohe = OneHotEncoder()\n",
    "Y_train = ohe.fit_transform(Y_train).toarray()\n",
    "Y_validation = ohe.transform(Y_validation).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = num_unique_word\n",
    "max_len = max_review_len\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(tweet['text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11712, 36)\n",
      "(2928, 36)\n"
     ]
    }
   ],
   "source": [
    "train_seq = tok.texts_to_sequences(X_train)\n",
    "val_seq = tok.texts_to_sequences(X_validation)\n",
    "## 将每个序列调整为相同的长度\n",
    "train_seq_mat = sequence.pad_sequences(train_seq,maxlen=max_len)\n",
    "val_seq_mat = sequence.pad_sequences(val_seq,maxlen=max_len)\n",
    "\n",
    "print(train_seq_mat.shape)\n",
    "print(val_seq_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 36, 300)           3885600   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, 36, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 36, 256)           439296    \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "d3 (Dense)                   (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,768,931\n",
      "Trainable params: 4,768,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#建立LSTM模型\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words+1, 300, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True,dropout=0.2, recurrent_dropout=0.2)))# 如果要加兩層，return_sequences=True\n",
    "# model.add(Dense(128, activation='relu',name='d1'))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(128, activation='relu',name='d2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu',name='d3'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11712 samples, validate on 2928 samples\n",
      "Epoch 1/40\n",
      "11712/11712 [==============================] - 14s 1ms/step - loss: 0.7588 - acc: 0.6705 - val_loss: 0.6515 - val_acc: 0.7391\n",
      "Epoch 2/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.5605 - acc: 0.7751 - val_loss: 0.5687 - val_acc: 0.7818\n",
      "Epoch 3/40\n",
      "11712/11712 [==============================] - 12s 995us/step - loss: 0.4564 - acc: 0.8280 - val_loss: 0.5663 - val_acc: 0.7927\n",
      "Epoch 4/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.3874 - acc: 0.8590 - val_loss: 0.7975 - val_acc: 0.7845\n",
      "Epoch 5/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.3385 - acc: 0.8780 - val_loss: 0.6427 - val_acc: 0.7903\n",
      "Epoch 6/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.2878 - acc: 0.8973 - val_loss: 0.6238 - val_acc: 0.7715\n",
      "Epoch 7/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.2592 - acc: 0.9106 - val_loss: 0.6624 - val_acc: 0.7801\n",
      "Epoch 8/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.2195 - acc: 0.9232 - val_loss: 0.7085 - val_acc: 0.7852\n",
      "Epoch 9/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.1906 - acc: 0.9343 - val_loss: 0.7317 - val_acc: 0.7626\n",
      "Epoch 10/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.1672 - acc: 0.9422 - val_loss: 0.8382 - val_acc: 0.7773\n",
      "Epoch 11/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.1465 - acc: 0.9497 - val_loss: 0.8725 - val_acc: 0.7613\n",
      "Epoch 12/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.1316 - acc: 0.9547 - val_loss: 1.0433 - val_acc: 0.7722\n",
      "Epoch 13/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.1197 - acc: 0.9599 - val_loss: 0.9224 - val_acc: 0.7561\n",
      "Epoch 14/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.1102 - acc: 0.9637 - val_loss: 1.0994 - val_acc: 0.7643\n",
      "Epoch 15/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0935 - acc: 0.9702 - val_loss: 1.2241 - val_acc: 0.7452\n",
      "Epoch 16/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.0843 - acc: 0.9725 - val_loss: 1.2553 - val_acc: 0.7654\n",
      "Epoch 17/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0829 - acc: 0.9752 - val_loss: 1.4358 - val_acc: 0.7555\n",
      "Epoch 18/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.0739 - acc: 0.9741 - val_loss: 1.2342 - val_acc: 0.7568\n",
      "Epoch 19/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0688 - acc: 0.9781 - val_loss: 1.5313 - val_acc: 0.7640\n",
      "Epoch 20/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.0660 - acc: 0.9794 - val_loss: 1.4805 - val_acc: 0.7558\n",
      "Epoch 21/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.0600 - acc: 0.9798 - val_loss: 1.4878 - val_acc: 0.7363\n",
      "Epoch 22/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0614 - acc: 0.9809 - val_loss: 1.4004 - val_acc: 0.7640\n",
      "Epoch 23/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.0510 - acc: 0.9842 - val_loss: 1.4703 - val_acc: 0.7391\n",
      "Epoch 24/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.0484 - acc: 0.9856 - val_loss: 1.5934 - val_acc: 0.7445\n",
      "Epoch 25/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.0464 - acc: 0.9843 - val_loss: 1.6349 - val_acc: 0.7650\n",
      "Epoch 26/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0488 - acc: 0.9844 - val_loss: 1.5419 - val_acc: 0.7599\n",
      "Epoch 27/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.0440 - acc: 0.9857 - val_loss: 1.7816 - val_acc: 0.7544\n",
      "Epoch 28/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.0420 - acc: 0.9870 - val_loss: 1.6411 - val_acc: 0.7592\n",
      "Epoch 29/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0407 - acc: 0.9874 - val_loss: 1.7209 - val_acc: 0.7531\n",
      "Epoch 30/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.0383 - acc: 0.9880 - val_loss: 1.7702 - val_acc: 0.7620\n",
      "Epoch 31/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.0421 - acc: 0.9879 - val_loss: 1.8379 - val_acc: 0.7377\n",
      "Epoch 32/40\n",
      "11712/11712 [==============================] - 12s 994us/step - loss: 0.0326 - acc: 0.9907 - val_loss: 2.0579 - val_acc: 0.7326\n",
      "Epoch 33/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.0326 - acc: 0.9894 - val_loss: 2.0430 - val_acc: 0.7377\n",
      "Epoch 34/40\n",
      "11712/11712 [==============================] - 12s 993us/step - loss: 0.0339 - acc: 0.9904 - val_loss: 1.7634 - val_acc: 0.7442\n",
      "Epoch 35/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.0364 - acc: 0.9881 - val_loss: 1.7829 - val_acc: 0.7503\n",
      "Epoch 36/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.0266 - acc: 0.9909 - val_loss: 2.0521 - val_acc: 0.7514\n",
      "Epoch 37/40\n",
      "11712/11712 [==============================] - 12s 990us/step - loss: 0.0313 - acc: 0.9906 - val_loss: 1.8099 - val_acc: 0.7456\n",
      "Epoch 38/40\n",
      "11712/11712 [==============================] - 12s 994us/step - loss: 0.0266 - acc: 0.9909 - val_loss: 2.0124 - val_acc: 0.7449\n",
      "Epoch 39/40\n",
      "11712/11712 [==============================] - 12s 991us/step - loss: 0.0298 - acc: 0.9911 - val_loss: 2.0197 - val_acc: 0.7520\n",
      "Epoch 40/40\n",
      "11712/11712 [==============================] - 12s 992us/step - loss: 0.0252 - acc: 0.9920 - val_loss: 2.0424 - val_acc: 0.7466\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_seq_mat,Y_train,batch_size=128,epochs=40,\n",
    "                      validation_data=(val_seq_mat,Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
